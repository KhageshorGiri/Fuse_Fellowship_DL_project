{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:21.164505Z","iopub.execute_input":"2023-07-28T13:57:21.164928Z","iopub.status.idle":"2023-07-28T13:57:33.400205Z","shell.execute_reply.started":"2023-07-28T13:57:21.164888Z","shell.execute_reply":"2023-07-28T13:57:33.398983Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os                       # for working with files\nimport numpy as np              # for numerical computationss\nimport pandas as pd             # for working with dataframes\nimport torch                    # Pytorch module \nimport matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\nimport torch.nn as nn           # for creating  neural networks\nfrom torch.utils.data import DataLoader # for dataloaders \nfrom PIL import Image           # for checking images\nimport torch.nn.functional as F # for functions for calculating loss\nimport torchvision.transforms as transforms   # for transforming images into tensors \nfrom torchvision.utils import make_grid       # for data checking\nfrom torchvision.datasets import ImageFolder  # for working with classes and images\nfrom torchsummary import summary    \n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:33.404278Z","iopub.execute_input":"2023-07-28T13:57:33.404605Z","iopub.status.idle":"2023-07-28T13:57:35.598369Z","shell.execute_reply.started":"2023-07-28T13:57:33.404574Z","shell.execute_reply":"2023-07-28T13:57:35.597230Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\ntrain_dir = data_dir + \"/train\"\nvalid_dir = data_dir + \"/valid\"\ndiseases = os.listdir(train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.603185Z","iopub.execute_input":"2023-07-28T13:57:35.603808Z","iopub.status.idle":"2023-07-28T13:57:35.620984Z","shell.execute_reply.started":"2023-07-28T13:57:35.603775Z","shell.execute_reply":"2023-07-28T13:57:35.620183Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# printing the disease names\nprint(diseases)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.626371Z","iopub.execute_input":"2023-07-28T13:57:35.628667Z","iopub.status.idle":"2023-07-28T13:57:35.637213Z","shell.execute_reply.started":"2023-07-28T13:57:35.628635Z","shell.execute_reply":"2023-07-28T13:57:35.636324Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['Tomato___Late_blight', 'Tomato___healthy', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Potato___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Tomato___Early_blight', 'Tomato___Septoria_leaf_spot', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Strawberry___Leaf_scorch', 'Peach___healthy', 'Apple___Apple_scab', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Bacterial_spot', 'Apple___Black_rot', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Peach___Bacterial_spot', 'Apple___Cedar_apple_rust', 'Tomato___Target_Spot', 'Pepper,_bell___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Potato___Late_blight', 'Tomato___Tomato_mosaic_virus', 'Strawberry___healthy', 'Apple___healthy', 'Grape___Black_rot', 'Potato___Early_blight', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Common_rust_', 'Grape___Esca_(Black_Measles)', 'Raspberry___healthy', 'Tomato___Leaf_Mold', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Pepper,_bell___Bacterial_spot', 'Corn_(maize)___healthy']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Total disease classes are: {}\".format(len(diseases)))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.641553Z","iopub.execute_input":"2023-07-28T13:57:35.642162Z","iopub.status.idle":"2023-07-28T13:57:35.650298Z","shell.execute_reply.started":"2023-07-28T13:57:35.642131Z","shell.execute_reply":"2023-07-28T13:57:35.649349Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total disease classes are: 38\n","output_type":"stream"}]},{"cell_type":"code","source":"plants = []\nNumberOfDiseases = 0\nfor plant in diseases:\n    if plant.split('___')[0] not in plants:\n        plants.append(plant.split('___')[0])\n    if plant.split('___')[1] != 'healthy':\n        NumberOfDiseases += 1","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.651971Z","iopub.execute_input":"2023-07-28T13:57:35.652802Z","iopub.status.idle":"2023-07-28T13:57:35.662889Z","shell.execute_reply.started":"2023-07-28T13:57:35.652711Z","shell.execute_reply":"2023-07-28T13:57:35.662009Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plants1 = []\nNumberOfDiseases = 0\nfor plant in diseases:\n    if plant.split('___')[0] not in plants1:\n        plants1.append(plant.split('___')[0])\nprint(plants1)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.664548Z","iopub.execute_input":"2023-07-28T13:57:35.665357Z","iopub.status.idle":"2023-07-28T13:57:35.679714Z","shell.execute_reply.started":"2023-07-28T13:57:35.665309Z","shell.execute_reply":"2023-07-28T13:57:35.678662Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['Tomato', 'Grape', 'Orange', 'Soybean', 'Squash', 'Potato', 'Corn_(maize)', 'Strawberry', 'Peach', 'Apple', 'Blueberry', 'Cherry_(including_sour)', 'Pepper,_bell', 'Raspberry']\n","output_type":"stream"}]},{"cell_type":"code","source":"# unique plants in the dataset\nprint(f\"Unique Plants are: \\n{plants}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.680961Z","iopub.execute_input":"2023-07-28T13:57:35.682113Z","iopub.status.idle":"2023-07-28T13:57:35.689781Z","shell.execute_reply.started":"2023-07-28T13:57:35.682082Z","shell.execute_reply":"2023-07-28T13:57:35.688717Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Unique Plants are: \n['Tomato', 'Grape', 'Orange', 'Soybean', 'Squash', 'Potato', 'Corn_(maize)', 'Strawberry', 'Peach', 'Apple', 'Blueberry', 'Cherry_(including_sour)', 'Pepper,_bell', 'Raspberry']\n","output_type":"stream"}]},{"cell_type":"code","source":"# datasets for validation and training\n#train = ImageFolder(train_dir, transform=transforms.ToTensor())\n#valid = ImageFolder(valid_dir, transform=transforms.ToTensor()) ","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.691593Z","iopub.execute_input":"2023-07-28T13:57:35.692277Z","iopub.status.idle":"2023-07-28T13:57:35.696990Z","shell.execute_reply.started":"2023-07-28T13:57:35.692232Z","shell.execute_reply":"2023-07-28T13:57:35.695932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#img, label = train[0]\n#print(img.shape, label)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.708358Z","iopub.execute_input":"2023-07-28T13:57:35.708952Z","iopub.status.idle":"2023-07-28T13:57:35.712673Z","shell.execute_reply.started":"2023-07-28T13:57:35.708923Z","shell.execute_reply":"2023-07-28T13:57:35.711820Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#type(train)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.714303Z","iopub.execute_input":"2023-07-28T13:57:35.715089Z","iopub.status.idle":"2023-07-28T13:57:35.720966Z","shell.execute_reply.started":"2023-07-28T13:57:35.715059Z","shell.execute_reply":"2023-07-28T13:57:35.719637Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#train.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.723095Z","iopub.execute_input":"2023-07-28T13:57:35.724416Z","iopub.status.idle":"2023-07-28T13:57:35.733576Z","shell.execute_reply.started":"2023-07-28T13:57:35.724384Z","shell.execute_reply":"2023-07-28T13:57:35.732662Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.735348Z","iopub.execute_input":"2023-07-28T13:57:35.736140Z","iopub.status.idle":"2023-07-28T13:57:35.741682Z","shell.execute_reply.started":"2023-07-28T13:57:35.736110Z","shell.execute_reply":"2023-07-28T13:57:35.740624Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, root_folder, transform=None):\n        self.root_folder = root_folder\n        self.transform = transform\n        self.classes, self.class_to_idx = self._find_classes()\n        self.samples = self._make_dataset()\n        self.categories_with_idx = self._get_categories()\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        image_path, target, class_name = self.samples[index]\n        image = Image.open(image_path)\n\n        if self.transform is not None:\n            image = self.transform(image)\n            \n        plant_category = class_name.split('___')[0]\n        all_categories = self._get_categories()\n        category_idx = all_categories[plant_category]\n        \n        return image, target, category_idx\n\n    def _get_categories(self):\n        categories = sorted(os.listdir(self.root_folder))\n        plants = []\n        for plant in categories:\n            if plant.split('___')[0] not in plants:\n                plants.append(plant.split('___')[0])\n        category_to_idx = {category_name: i for i, category_name in enumerate(plants)}\n        return category_to_idx\n    \n    def _find_classes(self):\n        classes = sorted(os.listdir(self.root_folder))\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx\n\n    def _make_dataset(self):\n        samples = []\n        for class_name in self.classes:\n            class_dir = os.path.join(self.root_folder, class_name)\n            if not os.path.isdir(class_dir):\n                continue\n\n            for image_name in os.listdir(class_dir):\n                image_path = os.path.join(class_dir, image_name)\n                if os.path.isfile(image_path):\n                    item = (image_path, self.class_to_idx[class_name], class_name)\n                    samples.append(item)\n\n        return samples\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.743520Z","iopub.execute_input":"2023-07-28T13:57:35.744818Z","iopub.status.idle":"2023-07-28T13:57:35.768117Z","shell.execute_reply.started":"2023-07-28T13:57:35.744786Z","shell.execute_reply":"2023-07-28T13:57:35.767117Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create custom dataset\nroot_folder = train_dir\ndataset = CustomDataset(root_folder=root_folder, transform=transforms.ToTensor())\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:57:35.769812Z","iopub.execute_input":"2023-07-28T13:57:35.770673Z","iopub.status.idle":"2023-07-28T13:59:25.048097Z","shell.execute_reply.started":"2023-07-28T13:57:35.770643Z","shell.execute_reply":"2023-07-28T13:59:25.047022Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"img, label, category = dataset[10000]\nprint(img.shape, label, category)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.049789Z","iopub.execute_input":"2023-07-28T13:59:25.050157Z","iopub.status.idle":"2023-07-28T13:59:25.110088Z","shell.execute_reply.started":"2023-07-28T13:59:25.050114Z","shell.execute_reply":"2023-07-28T13:59:25.109065Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"torch.Size([3, 256, 256]) 5 2\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.111787Z","iopub.execute_input":"2023-07-28T13:59:25.112179Z","iopub.status.idle":"2023-07-28T13:59:25.120611Z","shell.execute_reply.started":"2023-07-28T13:59:25.112146Z","shell.execute_reply":"2023-07-28T13:59:25.119647Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'Apple___Apple_scab': 0,\n 'Apple___Black_rot': 1,\n 'Apple___Cedar_apple_rust': 2,\n 'Apple___healthy': 3,\n 'Blueberry___healthy': 4,\n 'Cherry_(including_sour)___Powdery_mildew': 5,\n 'Cherry_(including_sour)___healthy': 6,\n 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7,\n 'Corn_(maize)___Common_rust_': 8,\n 'Corn_(maize)___Northern_Leaf_Blight': 9,\n 'Corn_(maize)___healthy': 10,\n 'Grape___Black_rot': 11,\n 'Grape___Esca_(Black_Measles)': 12,\n 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13,\n 'Grape___healthy': 14,\n 'Orange___Haunglongbing_(Citrus_greening)': 15,\n 'Peach___Bacterial_spot': 16,\n 'Peach___healthy': 17,\n 'Pepper,_bell___Bacterial_spot': 18,\n 'Pepper,_bell___healthy': 19,\n 'Potato___Early_blight': 20,\n 'Potato___Late_blight': 21,\n 'Potato___healthy': 22,\n 'Raspberry___healthy': 23,\n 'Soybean___healthy': 24,\n 'Squash___Powdery_mildew': 25,\n 'Strawberry___Leaf_scorch': 26,\n 'Strawberry___healthy': 27,\n 'Tomato___Bacterial_spot': 28,\n 'Tomato___Early_blight': 29,\n 'Tomato___Late_blight': 30,\n 'Tomato___Leaf_Mold': 31,\n 'Tomato___Septoria_leaf_spot': 32,\n 'Tomato___Spider_mites Two-spotted_spider_mite': 33,\n 'Tomato___Target_Spot': 34,\n 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35,\n 'Tomato___Tomato_mosaic_virus': 36,\n 'Tomato___healthy': 37}"},"metadata":{}}]},{"cell_type":"code","source":"plants = []\ncategories = sorted(os.listdir(root_folder))\nfor plant in categories:\n    if plant.split('___')[0] not in plants:\n        plants.append(plant.split('___')[0])\ncategory_to_idx = {category_name: i for i, category_name in enumerate(plants)}\ncategory_to_idx","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.122365Z","iopub.execute_input":"2023-07-28T13:59:25.123041Z","iopub.status.idle":"2023-07-28T13:59:25.133417Z","shell.execute_reply.started":"2023-07-28T13:59:25.123008Z","shell.execute_reply":"2023-07-28T13:59:25.132320Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'Apple': 0,\n 'Blueberry': 1,\n 'Cherry_(including_sour)': 2,\n 'Corn_(maize)': 3,\n 'Grape': 4,\n 'Orange': 5,\n 'Peach': 6,\n 'Pepper,_bell': 7,\n 'Potato': 8,\n 'Raspberry': 9,\n 'Soybean': 10,\n 'Squash': 11,\n 'Strawberry': 12,\n 'Tomato': 13}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet50\nfrom torchvision import transforms, datasets\n\n# Define the Multi-Level ResNet Model\nclass MultiLevelResNet(nn.Module):\n    def __init__(self):\n        super(MultiLevelResNet, self).__init__()\n        self.resnet = resnet50(pretrained=True)\n        self.fc_category = nn.Linear(1000, 14)\n        self.fc_disease = nn.Linear(1000, 38)\n\n    def forward(self, x):\n        features = self.resnet(x)\n        category_output = self.fc_category(features)\n        disease_output = self.fc_disease(features)\n        return category_output, disease_output","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.136534Z","iopub.execute_input":"2023-07-28T13:59:25.136796Z","iopub.status.idle":"2023-07-28T13:59:25.148674Z","shell.execute_reply.started":"2023-07-28T13:59:25.136774Z","shell.execute_reply":"2023-07-28T13:59:25.147600Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Set hyperparameters\nbatch_size = 32\nlearning_rate = 0.001\nnum_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.150668Z","iopub.execute_input":"2023-07-28T13:59:25.150922Z","iopub.status.idle":"2023-07-28T13:59:25.155613Z","shell.execute_reply.started":"2023-07-28T13:59:25.150900Z","shell.execute_reply":"2023-07-28T13:59:25.154676Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Setting the seed value\nrandom_seed = 7\ntorch.manual_seed(random_seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.156881Z","iopub.execute_input":"2023-07-28T13:59:25.157894Z","iopub.status.idle":"2023-07-28T13:59:25.171136Z","shell.execute_reply.started":"2023-07-28T13:59:25.157859Z","shell.execute_reply":"2023-07-28T13:59:25.170314Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e14c8d56a70>"},"metadata":{}}]},{"cell_type":"code","source":"# datasets for validation and training\ntrain = CustomDataset(train_dir, transform=transforms.ToTensor())\nvalid = CustomDataset(valid_dir, transform=transforms.ToTensor()) ","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:25.172178Z","iopub.execute_input":"2023-07-28T13:59:25.172444Z","iopub.status.idle":"2023-07-28T13:59:54.997728Z","shell.execute_reply.started":"2023-07-28T13:59:25.172423Z","shell.execute_reply":"2023-07-28T13:59:54.996729Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# for checking some images from training dataset\ndef show_image(image, label):\n    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n    plt.imshow(image.permute(1, 2, 0))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:54.999574Z","iopub.execute_input":"2023-07-28T13:59:54.999932Z","iopub.status.idle":"2023-07-28T13:59:55.006690Z","shell.execute_reply.started":"2023-07-28T13:59:54.999898Z","shell.execute_reply":"2023-07-28T13:59:55.005512Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"img, label, category = train[0]\nprint(img.shape, label, category)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.008581Z","iopub.execute_input":"2023-07-28T13:59:55.009125Z","iopub.status.idle":"2023-07-28T13:59:55.024638Z","shell.execute_reply.started":"2023-07-28T13:59:55.009086Z","shell.execute_reply":"2023-07-28T13:59:55.023796Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"torch.Size([3, 256, 256]) 0 0\n","output_type":"stream"}]},{"cell_type":"code","source":"# DataLoaders for training and validation\ntrain_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.026864Z","iopub.execute_input":"2023-07-28T13:59:55.027567Z","iopub.status.idle":"2023-07-28T13:59:55.033413Z","shell.execute_reply.started":"2023-07-28T13:59:55.027532Z","shell.execute_reply":"2023-07-28T13:59:55.032445Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# helper function to show a batch of training instances\ndef show_batch(data):\n    for images, labels in data:\n        fig, ax = plt.subplots(figsize=(30, 30))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n        break","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.034945Z","iopub.execute_input":"2023-07-28T13:59:55.035448Z","iopub.status.idle":"2023-07-28T13:59:55.044088Z","shell.execute_reply.started":"2023-07-28T13:59:55.035413Z","shell.execute_reply":"2023-07-28T13:59:55.043201Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# for moving data into GPU (if available)\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available:\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n\n# for moving data to device (CPU or GPU)\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# for loading in the device (GPU if available else CPU)\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n        \n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.046915Z","iopub.execute_input":"2023-07-28T13:59:55.047228Z","iopub.status.idle":"2023-07-28T13:59:55.057488Z","shell.execute_reply.started":"2023-07-28T13:59:55.047203Z","shell.execute_reply":"2023-07-28T13:59:55.056418Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.063979Z","iopub.execute_input":"2023-07-28T13:59:55.064678Z","iopub.status.idle":"2023-07-28T13:59:55.070847Z","shell.execute_reply.started":"2023-07-28T13:59:55.064647Z","shell.execute_reply":"2023-07-28T13:59:55.069913Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.072137Z","iopub.execute_input":"2023-07-28T13:59:55.072995Z","iopub.status.idle":"2023-07-28T13:59:55.078331Z","shell.execute_reply.started":"2023-07-28T13:59:55.072962Z","shell.execute_reply":"2023-07-28T13:59:55.077197Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# for calculating the accuracy\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\n# base class for the model\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                   # Generate prediction\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        acc = accuracy(out, labels)          # Calculate accuracy\n        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x[\"val_loss\"] for x in outputs]\n        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n        epoch_accuracy = torch.stack(batch_accuracy).mean()\n        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.079772Z","iopub.execute_input":"2023-07-28T13:59:55.080562Z","iopub.status.idle":"2023-07-28T13:59:55.092307Z","shell.execute_reply.started":"2023-07-28T13:59:55.080492Z","shell.execute_reply":"2023-07-28T13:59:55.091301Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Architecture for training\n\n# convolution block with BatchNormalization\ndef ConvBlock(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool:\n        layers.append(nn.MaxPool2d(4))\n    return nn.Sequential(*layers)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.095470Z","iopub.execute_input":"2023-07-28T13:59:55.095729Z","iopub.status.idle":"2023-07-28T13:59:55.103869Z","shell.execute_reply.started":"2023-07-28T13:59:55.095707Z","shell.execute_reply":"2023-07-28T13:59:55.102923Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n# resnet architecture \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_diseases):\n        super().__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 64)\n        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n        \n        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                       nn.Flatten(),\n                                       nn.Linear(512, num_diseases))\n        \n    def forward(self, xb): # xb is the loaded batch\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out  ","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.105481Z","iopub.execute_input":"2023-07-28T13:59:55.106483Z","iopub.status.idle":"2023-07-28T13:59:55.116116Z","shell.execute_reply.started":"2023-07-28T13:59:55.106450Z","shell.execute_reply":"2023-07-28T13:59:55.115312Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# defining the model and moving it to the GPU\nmodel = to_device(ResNet9(3, len(train.classes)), device) \nmodel","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:55.118184Z","iopub.execute_input":"2023-07-28T13:59:55.119943Z","iopub.status.idle":"2023-07-28T13:59:57.875801Z","shell.execute_reply.started":"2023-07-28T13:59:55.119916Z","shell.execute_reply":"2023-07-28T13:59:57.874905Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"ResNet9(\n  (conv1): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n  )\n  (res1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (conv3): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv4): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n  )\n  (res2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): Linear(in_features=512, out_features=38, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# getting summary of the model\nINPUT_SHAPE = (3, 256, 256)\nprint(summary(model.cuda(), (INPUT_SHAPE)))","metadata":{"execution":{"iopub.status.busy":"2023-07-28T13:59:57.877219Z","iopub.execute_input":"2023-07-28T13:59:57.878268Z","iopub.status.idle":"2023-07-28T14:00:01.991962Z","shell.execute_reply.started":"2023-07-28T13:59:57.878228Z","shell.execute_reply":"2023-07-28T14:00:01.990181Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 256, 256]           1,792\n       BatchNorm2d-2         [-1, 64, 256, 256]             128\n              ReLU-3         [-1, 64, 256, 256]               0\n            Conv2d-4        [-1, 128, 256, 256]          73,856\n       BatchNorm2d-5        [-1, 128, 256, 256]             256\n              ReLU-6        [-1, 128, 256, 256]               0\n         MaxPool2d-7          [-1, 128, 64, 64]               0\n            Conv2d-8          [-1, 128, 64, 64]         147,584\n       BatchNorm2d-9          [-1, 128, 64, 64]             256\n             ReLU-10          [-1, 128, 64, 64]               0\n           Conv2d-11          [-1, 128, 64, 64]         147,584\n      BatchNorm2d-12          [-1, 128, 64, 64]             256\n             ReLU-13          [-1, 128, 64, 64]               0\n           Conv2d-14          [-1, 256, 64, 64]         295,168\n      BatchNorm2d-15          [-1, 256, 64, 64]             512\n             ReLU-16          [-1, 256, 64, 64]               0\n        MaxPool2d-17          [-1, 256, 16, 16]               0\n           Conv2d-18          [-1, 512, 16, 16]       1,180,160\n      BatchNorm2d-19          [-1, 512, 16, 16]           1,024\n             ReLU-20          [-1, 512, 16, 16]               0\n        MaxPool2d-21            [-1, 512, 4, 4]               0\n           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n             ReLU-24            [-1, 512, 4, 4]               0\n           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n             ReLU-27            [-1, 512, 4, 4]               0\n        MaxPool2d-28            [-1, 512, 1, 1]               0\n          Flatten-29                  [-1, 512]               0\n           Linear-30                   [-1, 38]          19,494\n================================================================\nTotal params: 6,589,734\nTrainable params: 6,589,734\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 343.95\nParams size (MB): 25.14\nEstimated Total Size (MB): 369.83\n----------------------------------------------------------------\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# for training\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \n\ndef fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n                grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # scheduler for one cycle learniing rate\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    \n    for epoch in range(epochs):\n        # Training\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n    \n        # validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n    return history\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:00:01.994132Z","iopub.execute_input":"2023-07-28T14:00:01.995171Z","iopub.status.idle":"2023-07-28T14:00:02.006442Z","shell.execute_reply.started":"2023-07-28T14:00:01.995135Z","shell.execute_reply":"2023-07-28T14:00:02.005315Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:00:02.007954Z","iopub.execute_input":"2023-07-28T14:00:02.008516Z","iopub.status.idle":"2023-07-28T14:00:03.058190Z","shell.execute_reply.started":"2023-07-28T14:00:02.008480Z","shell.execute_reply":"2023-07-28T14:00:03.056376Z"},"trusted":true},"execution_count":38,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m<timed exec>:1\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, val_loader):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mvalidation_step(batch) \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvalidation_epoch_end(outputs)\n","Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, val_loader):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 5\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvalidation_epoch_end(outputs)\n","Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mImageClassificationBase.validation_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m---> 17\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(images)                   \u001b[38;5;66;03m# Generate prediction\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out, labels)  \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}]},{"cell_type":"code","source":"epochs = 2\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:00:03.060517Z","iopub.execute_input":"2023-07-28T14:00:03.061098Z","iopub.status.idle":"2023-07-28T14:00:03.071537Z","shell.execute_reply.started":"2023-07-28T14:00:03.061047Z","shell.execute_reply":"2023-07-28T14:00:03.070305Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory += fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=1e-4, \n                             opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:00:03.073117Z","iopub.execute_input":"2023-07-28T14:00:03.074193Z","iopub.status.idle":"2023-07-28T14:00:03.112198Z","shell.execute_reply.started":"2023-07-28T14:00:03.074158Z","shell.execute_reply":"2023-07-28T14:00:03.111321Z"},"trusted":true},"execution_count":40,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m<timed exec>:1\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:25:01.609786Z","iopub.execute_input":"2023-07-28T14:25:01.610170Z","iopub.status.idle":"2023-07-28T14:25:01.615952Z","shell.execute_reply.started":"2023-07-28T14:25:01.610140Z","shell.execute_reply":"2023-07-28T14:25:01.614572Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, 2 + 1):\n    model.train()\n    for images, labels, category in train_dl:\n        images = images.to(device)\n        labels = labels.to(device)\n        category = category.to(device)\n        \n        optimizer.zero_grad()\n        disease_output  = model(images)\n        #print(disease_output, plant_output)\n        #break\n        disease_loss= criterion(disease_output, labels)\n        #plant_loss = criterion(category_output, category)\n\n        loss = disease_loss #+ plant_loss\n\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for images, labels, category in valid_dl:\n            images = images.to(device)\n            labels = labels.to(device)\n            category = category.to(device)\n            \n            disease_output = model(images)\n\n            _, disease_predicted = torch.max(disease_output, 1)\n           # _, plant_predicted = torch.max(plant_output, 1)\n\n            total_correct += (disease_predicted == labels).sum().item() # + (plant_predicted == category).sum().item()\n            total_samples += labels.size(0) * 2\n\n    accuracy = 100.0 * total_correct / total_samples\n    print(f\"Epoch: {epoch}, Accuracy: {accuracy:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-28T14:25:26.632302Z","iopub.execute_input":"2023-07-28T14:25:26.633247Z","iopub.status.idle":"2023-07-28T14:42:58.060312Z","shell.execute_reply.started":"2023-07-28T14:25:26.633209Z","shell.execute_reply":"2023-07-28T14:42:58.058997Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch: 1, Accuracy: 46.43%\nEpoch: 2, Accuracy: 46.99%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}